{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df19a9e-27a8-4869-adc6-c6b9e76f48b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "from autogluon.vision import ImagePredictor, ImageDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from cleanlab.count import get_confident_thresholds\n",
    "from cleanlab.internal.label_quality_utils import get_normalized_entropy\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7895ad-11e9-4454-90cb-c7c33dae84d9",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db9dfd-303c-43c2-9439-05a994dee909",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = \"swin_base_patch4_window7_224\" # uses Torch backend\n",
    "# model = \"resnet50_v1\" # uses MXNET backend\n",
    "\n",
    "data_model_dict = {\n",
    "    \"cifar-10\": {\"data_path\": \"/datasets/uly/ood-data/cifar10_png/\"},\n",
    "    \"cifar-100\": {\"data_path\": \"/datasets/uly/ood-data/cifar100_png/\"},\n",
    "    \"mnist\": {\"data_path\": \"/datasets/uly/ood-data/mnist_png/\"},\n",
    "    \"fashion-mnist\": {\"data_path\": \"/datasets/uly/ood-data/fashion_mnist_png/\"}\n",
    "}\n",
    "\n",
    "# Get data, model, and pre-trained features\n",
    "for dataset in data_model_dict.keys():\n",
    "    \n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Getting data for {dataset}\")\n",
    "    \n",
    "    # Get path to data\n",
    "    data_path = data_model_dict[dataset][\"data_path\"]\n",
    "    \n",
    "    # Get train and test data\n",
    "    data_model_dict[dataset][\"train_data\"], _, data_model_dict[dataset][\"test_data\"] = \\\n",
    "        ImageDataset.from_folders(root=data_path)\n",
    "    \n",
    "    # Get path to saved model\n",
    "    data_model_dict[dataset][\"model\"] = f\"./models/{model}_{dataset}.ag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cace151-c2b3-476d-9c4b-0a49f8ca7acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0446d-8978-449f-b8c5-0cbdd97d46be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d426f01d-d145-4d18-a265-0b8c866114db",
   "metadata": {},
   "source": [
    "## Evaluate models on test data as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533948d-5031-4de5-bb1c-0b0ce9eb259a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accuracy_result_list = []\n",
    "\n",
    "for key, data in data_model_dict.items():\n",
    "    dataset = key\n",
    "\n",
    "    model_path = data[\"model\"]\n",
    "    test_dataset = data[\"test_data\"]\n",
    "    \n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    \n",
    "    # load model\n",
    "    print(\"  Loading model...\")\n",
    "    predictor_loaded = ImagePredictor.load(model_path)\n",
    "    \n",
    "    # evaluating model on test data\n",
    "    print(\"  Evaluating model...\")\n",
    "    eval_ = predictor_loaded.evaluate(test_dataset)\n",
    "    print(f\"    Evaluation: {eval_}\")\n",
    "    \n",
    "    accuracy_result = {\n",
    "        \"dataset\": dataset,\n",
    "        \"top1\": eval_[\"top1\"]\n",
    "    }\n",
    "    \n",
    "    accuracy_result_list.append(accuracy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99027a0-8bac-476b-972d-e7a94eaae158",
   "metadata": {},
   "source": [
    "## Evaluate OOD Scores on TEST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2932f76-a8c7-4009-bff1-f672da79923a",
   "metadata": {},
   "source": [
    "## Save the pred_probs used for OOD scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bea89-2597-4163-9f53-b93090c233b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# pairs of (in-distribution, out-of-distribution) datasets to evaluate\n",
    "in_out_pairs = [\n",
    "    {\"in\": \"cifar-10\", \"out\": \"cifar-100\"},\n",
    "    {\"in\": \"cifar-100\", \"out\": \"cifar-10\"},\n",
    "    {\"in\": \"mnist\", \"out\": \"fashion-mnist\"},\n",
    "    {\"in\": \"fashion-mnist\", \"out\": \"mnist\"},\n",
    "]\n",
    "\n",
    "for in_out_pair in in_out_pairs:\n",
    "    \n",
    "    in_dataset, out_dataset = in_out_pair[\"in\"], in_out_pair[\"out\"]\n",
    "    \n",
    "    # path to model trained on in-distribution train dataset\n",
    "    in_model_path = data_model_dict[in_dataset][\"model\"]\n",
    "\n",
    "    # get in-distribution TRAIN dataset\n",
    "    in_train_dataset = data_model_dict[in_dataset][\"train_data\"]\n",
    "    in_train_dataset_class_labels = in_train_dataset.label.values # class labels for the in-distribution train dataset\n",
    "    \n",
    "    # get TEST datasets used for evaluation\n",
    "    in_test_dataset = data_model_dict[in_dataset][\"test_data\"]\n",
    "    in_test_dataset_class_labels = in_test_dataset.label.values # class labels for the in-distribution test dataset\n",
    "\n",
    "    out_test_dataset = data_model_dict[out_dataset][\"test_data\"]\n",
    "    \n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"(in-distribution, out-of-distribution) dataset pair: \", in_dataset, out_dataset)\n",
    "    \n",
    "    # load model (trained on training set)\n",
    "    print(\"  Loading model...\")\n",
    "    in_predictor_loaded = ImagePredictor.load(in_model_path)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    print(\"  Generating predicted probabilities...\")\n",
    "    in_train_pred_probs = in_predictor_loaded.predict_proba(data=in_train_dataset, as_pandas=False)    \n",
    "    in_test_pred_probs = in_predictor_loaded.predict_proba(data=in_test_dataset, as_pandas=False)\n",
    "    out_test_pred_probs = in_predictor_loaded.predict_proba(data=out_test_dataset, as_pandas=False)\n",
    "    \n",
    "    # Save files here\n",
    "    out_folder = f\"./model_{model}_experiment_in_{in_dataset}_out_{out_dataset}/\"\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    \n",
    "    #### Uncomment below to save files\n",
    "\n",
    "    np.save(out_folder + \"in_train_pred_probs.npy\", in_train_pred_probs)\n",
    "    np.save(out_folder + \"in_test_pred_probs.npy\", in_test_pred_probs)\n",
    "    np.save(out_folder + \"out_test_pred_probs.npy\", out_test_pred_probs)\n",
    "    \n",
    "    np.save(out_folder + \"in_train_dataset_class_labels.npy\", in_train_dataset_class_labels)\n",
    "    np.save(out_folder + \"in_test_dataset_class_labels.npy\", in_test_dataset_class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47837b90-a36f-4c50-a966-33f09b2bb31a",
   "metadata": {},
   "source": [
    "## Run OOD scoring on loaded pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18e806-4a90-4662-88ed-bd092593a439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(p, q):\n",
    "    return -np.sum(p * np.log(q)) / q.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298896e-4a98-4de8-93e9-26dc3e5fd2b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# pairs of (in-distribution, out-of-distribution) datasets to evaluate\n",
    "in_out_pairs = [\n",
    "    {\"in\": \"cifar-10\", \"out\": \"cifar-100\"},\n",
    "    {\"in\": \"cifar-100\", \"out\": \"cifar-10\"},\n",
    "    {\"in\": \"mnist\", \"out\": \"fashion-mnist\"},\n",
    "    {\"in\": \"fashion-mnist\", \"out\": \"mnist\"},\n",
    "]\n",
    "\n",
    "k_max = 110\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for in_out_pair in in_out_pairs:\n",
    "    \n",
    "    in_dataset, out_dataset = in_out_pair[\"in\"], in_out_pair[\"out\"]\n",
    "    \n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"(in-distribution, out-of-distribution) dataset pair: \", in_dataset, out_dataset)\n",
    "    \n",
    "    # Save files here\n",
    "    out_folder = f\"./model_{model}_experiment_in_{in_dataset}_out_{out_dataset}/\"\n",
    "    \n",
    "    # Load files\n",
    "    in_train_pred_probs = np.load(out_folder + \"in_train_pred_probs.npy\")\n",
    "    in_test_pred_probs = np.load(out_folder + \"in_test_pred_probs.npy\")\n",
    "    out_test_pred_probs = np.load(out_folder + \"out_test_pred_probs.npy\")\n",
    "    \n",
    "    in_train_dataset_class_labels = np.load(out_folder + \"in_train_dataset_class_labels.npy\")\n",
    "    in_test_dataset_class_labels = np.load(out_folder + \"in_test_dataset_class_labels.npy\")\n",
    "    \n",
    "    # Create OOD binary labels (1 = out-of-distribution)\n",
    "    in_labels = np.zeros(shape=len(in_test_pred_probs))\n",
    "    out_labels = np.ones(shape=len(out_test_pred_probs))\n",
    "    ood_mask = np.hstack([in_labels, out_labels]).astype(int) # OOD binary indicator\n",
    "\n",
    "    #### Compute nearest neighbors\n",
    "    \n",
    "    #### Get scores\n",
    "    \n",
    "    # Adjusted MSP & Entropy in confidence thresholds\n",
    "    class_confident_thresholds = get_confident_thresholds(in_train_dataset_class_labels, in_train_pred_probs, multi_label=False)\n",
    "    \n",
    "    # Train Entropy\n",
    "    in_train_entropy = get_normalized_entropy(in_train_pred_probs)\n",
    "    \n",
    "    #### Get scores for test dataset\n",
    "    \n",
    "    # 1 - Max Pred Probs\n",
    "    test_one_minus_max_pred_prob = 1. - test_pred_probs.max(axis=1)\n",
    "\n",
    "    # Entropy\n",
    "    test_entropy = get_normalized_entropy(test_pred_probs)\n",
    "\n",
    "    # Adjust pred-probs for Adjusted MSP and Entropy\n",
    "    test_pred_probs_adj = test_pred_probs - class_confident_thresholds\n",
    "    test_pred_probs_adj += class_confident_thresholds.max()\n",
    "    test_pred_probs_adj /= test_pred_probs_adj.sum(axis=1)[:, None]\n",
    "    \n",
    "    # Adjusted MSP\n",
    "    test_adj_msp = 1. - test_pred_probs_adj.max(axis=1)\n",
    "    \n",
    "    # Adjusted Entropy\n",
    "    test_adj_entropy =  get_normalized_entropy(test_pred_probs_adj)\n",
    "    \n",
    "    #### Evaluate scores\n",
    "    \n",
    "    auroc_test_one_minus_max_pred_prob = roc_auc_score(ood_mask, test_one_minus_max_pred_prob)\n",
    "    auroc_test_entropy = roc_auc_score(ood_mask, test_entropy)\n",
    "    auroc_test_adj_one_minus_max_pred_prob = roc_auc_score(ood_mask, test_adj_msp)\n",
    "    auroc_test_adj_entropy = roc_auc_score(ood_mask, test_adj_entropy)\n",
    "    \n",
    "    results = {\n",
    "        \"in_distribution\": in_dataset,\n",
    "        \"out_of_distribution\": out_dataset,\n",
    "\n",
    "        \"auroc_test_one_minus_max_pred_prob\": auroc_test_one_minus_max_pred_prob,\n",
    "        \"auroc_test_entropy\": auroc_test_entropy,\n",
    "        \n",
    "        \"auroc_test_adj_mst\": auroc_test_adj_one_minus_max_pred_prob,\n",
    "        \"auroc_test_adj_entropy\": auroc_test_adj_entropy,\n",
    "    }\n",
    "    \n",
    "    results_list.append(results)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe3ea0-0fc4-47e0-bd18-cdcae835d106",
   "metadata": {},
   "source": [
    "## Put results to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079c3ea-edd5-49f0-8d4f-42f8d22ee04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aac17a-316a-4871-b4c9-c574c92f36eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'in_distribution',\n",
    "    'out_of_distribution',\n",
    "    'auroc_test_one_minus_max_pred_prob',\n",
    "    'auroc_test_entropy',\n",
    "    'auroc_test_adj_mst',\n",
    "    'auroc_test_adj_entropy',\n",
    "]\n",
    "\n",
    "cols_rename_dict = {\n",
    "    'in_distribution': 'In Distribution',\n",
    "    'out_of_distribution': 'Out of Distribution',\n",
    "    'auroc_test_one_minus_max_pred_prob': 'MSP',\n",
    "    'auroc_test_entropy': 'Entropy',\n",
    "    'auroc_test_adj_mst' : 'Adjusted MSP',\n",
    "    'auroc_test_adj_entropy': 'Adjusted Entropy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fc4e8-28d7-430b-9cb8-c8c473a66681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename columns before exporting to latex\n",
    "df_results[cols].rename(columns=cols_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01185bb-622c-4f87-b19f-acc0cd0fd2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write to Latex file\n",
    "with open(f\"{model}_ood_auroc.tex\", \"w\") as tf:\n",
    "    tf.write(df_results[cols].rename(columns=cols_rename_dict).to_latex(index=False, float_format=\"%.4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
