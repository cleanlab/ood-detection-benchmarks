{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfbac00-f99d-45d8-a621-2671c27c2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "from autogluon.vision import ImagePredictor, ImageDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from cleanlab.internal.label_quality_utils import get_normalized_entropy\n",
    "\n",
    "from approximate_nearest_neighbors import ApproxNearestNeighbors\n",
    "\n",
    "# pre-trained model\n",
    "from image_feature_extraction.extract_features_from_image_dir import extract_features_from_image_dir\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7895ad-11e9-4454-90cb-c7c33dae84d9",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2db9dfd-303c-43c2-9439-05a994dee909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Getting data for cifar-10\n",
      "Extracting pre-trained embeddings...\n",
      "Function: init_data_loader_from_image_folder, Time: 0.3103651300043566 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.3106159250019118 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 33.73509187999298 Seconds\n",
      "Function: init_data_loader_from_image_folder, Time: 0.06405507599993143 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.06429411900171544 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 5.223168789001647 Seconds\n",
      "--------------------------\n",
      "Getting data for cifar-100\n",
      "Extracting pre-trained embeddings...\n",
      "Function: init_data_loader_from_image_folder, Time: 0.3105279080045875 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.3107110170094529 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 24.557706528008566 Seconds\n",
      "Function: init_data_loader_from_image_folder, Time: 0.0652280200010864 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.06541212699085008 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 5.158221752993995 Seconds\n",
      "--------------------------\n",
      "Getting data for roman-numeral\n",
      "Extracting pre-trained embeddings...\n",
      "Function: init_data_loader_from_image_folder, Time: 0.015309087990317494 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.015499098997679539 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 2.887093443001504 Seconds\n",
      "Function: init_data_loader_from_image_folder, Time: 0.017234450002433732 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.0174228139949264 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 3.3772088080004323 Seconds\n",
      "--------------------------\n",
      "Getting data for mnist\n",
      "Extracting pre-trained embeddings...\n",
      "Function: init_data_loader_from_image_folder, Time: 0.3762280389928492 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.37642371299443766 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 28.63511177401233 Seconds\n",
      "Function: init_data_loader_from_image_folder, Time: 0.06318879500031471 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.06337376199371647 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 4.988341887990828 Seconds\n",
      "--------------------------\n",
      "Getting data for fashion-mnist\n",
      "Extracting pre-trained embeddings...\n",
      "Function: init_data_loader_from_image_folder, Time: 0.3755347330006771 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.37571845900674816 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 28.908391689998098 Seconds\n",
      "Function: init_data_loader_from_image_folder, Time: 0.08133228099904954 Seconds\n",
      "Function: read_images_as_data_loader, Time: 0.08156460299505852 Seconds\n",
      "Starting ONNX runtime engine...\n",
      "  ONNX runtime device: GPU\n",
      "  ONNX runtime session providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Extracting features...\n",
      "Function: extract_features_from_image_dir, Time: 5.193756565000513 Seconds\n"
     ]
    }
   ],
   "source": [
    "model = \"swin_base_patch4_window7_224\" \n",
    "\n",
    "data_model_dict = {\n",
    "    \"cifar-10\": {\"data_path\": \"/Data/cifar10_png/\"},\n",
    "    \"cifar-100\": {\"data_path\": \"/Data/cifar100_png/\"},\n",
    "    \"roman-numeral\": {\"data_path\": \"/Data/andrew-ng-dcai-comp-2021-data-deduped/andrew-ng-dcai-comp-2021-data/\"},\n",
    "    \"mnist\": {\"data_path\": \"/Data/mnist_png/mnist_png/\"},\n",
    "    \"fashion-mnist\": {\"data_path\": \"/Data/fashion_mnist_png/\"}\n",
    "}\n",
    "\n",
    "# path to pre-trained model in ONNX format\n",
    "path_to_onnx = \"../../image_feature_extraction/models/feature_extractor.onnx\"\n",
    "\n",
    "# Get data, model, and pre-trained features\n",
    "for dataset in data_model_dict.keys():\n",
    "    \n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Getting data for {dataset}\")\n",
    "    \n",
    "    # Get path to data\n",
    "    data_path = data_model_dict[dataset][\"data_path\"]\n",
    "    \n",
    "    # Get train and test data\n",
    "    data_model_dict[dataset][\"train_data\"], _, data_model_dict[dataset][\"test_data\"] = \\\n",
    "        ImageDataset.from_folders(root=data_path)\n",
    "    \n",
    "    # Get path to saved model\n",
    "    data_model_dict[dataset][\"model\"] = f\"./autogluon_models/{model}_{dataset}.ag\"\n",
    "    \n",
    "    # Get pre-trained features; ResNet50 model pre-trained on ImageNet\n",
    "    # NOTE: we will compare these with LEARNED embeddings from the trained model (see below)\n",
    "    print(f\"Extracting pre-trained embeddings...\")\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        data_model_dict[dataset][f\"{split}_data_pretrained_features\"], _, _ = \\\n",
    "            extract_features_from_image_dir(path_to_onnx=path_to_onnx, path_to_image_dir=f\"{data_path}{split}/\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0446d-8978-449f-b8c5-0cbdd97d46be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d426f01d-d145-4d18-a265-0b8c866114db",
   "metadata": {},
   "source": [
    "## Evaluate models on test data as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b533948d-5031-4de5-bb1c-0b0ce9eb259a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cifar-10\n",
      "  Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24] validation: top1=0.988700 top5=0.999900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation: {'loss': 0.11967918761968613, 'top1': 0.9887, 'top5': 0.9999}\n",
      "Dataset: cifar-100\n",
      "  Loading model...\n",
      "  Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17] validation: top1=0.928600 top5=0.993300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation: {'loss': 0.33964193670749665, 'top1': 0.9286, 'top5': 0.9933}\n",
      "Dataset: roman-numeral\n",
      "  Loading model...\n",
      "  Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26] validation: top1=0.796694 top5=0.980579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation: {'loss': 0.6779465489643665, 'top1': 0.7966942148760331, 'top5': 0.9805785123966942}\n",
      "Dataset: mnist\n",
      "  Loading model...\n",
      "  Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24] validation: top1=0.991400 top5=1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation: {'loss': 0.11047064321041107, 'top1': 0.9914, 'top5': 1.0}\n",
      "Dataset: fashion-mnist\n",
      "  Loading model...\n",
      "  Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37] validation: top1=0.948900 top5=0.999700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation: {'loss': 0.2166707287788391, 'top1': 0.9489, 'top5': 0.9997}\n"
     ]
    }
   ],
   "source": [
    "accuracy_result_list = []\n",
    "\n",
    "for key, val in data_model_dict.items():\n",
    "    \n",
    "    dataset = key\n",
    "    model_path = val[\"model\"]\n",
    "    test_dataset = val[\"test_data\"]\n",
    "    \n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    \n",
    "    # load model\n",
    "    print(\"  Loading model...\")\n",
    "    predictor_loaded = ImagePredictor.load(model_path)\n",
    "    \n",
    "    # evaluating model on test data\n",
    "    print(\"  Evaluating model...\")\n",
    "    eval_ = predictor_loaded.evaluate(test_dataset)\n",
    "    print(f\"    Evaluation: {eval_}\")\n",
    "    \n",
    "    accuracy_result = {\n",
    "        \"dataset\": dataset,\n",
    "        \"top1\": eval_[\"top1\"]\n",
    "    }\n",
    "    \n",
    "    accuracy_result_list.append(accuracy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0ab5c-cb18-42e3-8f7e-4e2f05b81408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d99027a0-8bac-476b-972d-e7a94eaae158",
   "metadata": {},
   "source": [
    "## Evaluate OOD Scores on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe4956a7-b3d1-4cb1-8ca4-8e1d0aa0521e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  cifar-10 cifar-100\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n",
      "  Extracting learned embeddings...\n",
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  cifar-100 cifar-10\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/autogluon/vision/predictor/predictor.py:548: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  y_pred_proba[list(self._label_cleaner.cat_mappings_dependent_var.values())] = y_pred_proba['image_proba'].to_list()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracting learned embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/autogluon/vision/predictor/predictor.py:548: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  y_pred_proba[list(self._label_cleaner.cat_mappings_dependent_var.values())] = y_pred_proba['image_proba'].to_list()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  mnist roman-numeral\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n",
      "  Extracting learned embeddings...\n",
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  roman-numeral mnist\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n",
      "  Extracting learned embeddings...\n",
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  mnist fashion-mnist\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n",
      "  Extracting learned embeddings...\n",
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "-----------------------------------------------------\n",
      "(in-distribution, out-of-distribution) dataset pair:  fashion-mnist mnist\n",
      "  Loading model...\n",
      "  Generating predicted probabilities...\n",
      "  Extracting learned embeddings...\n",
      "  Running nearest neighbors search...\n",
      "Building nearest neighbors index\n",
      "  Generating scores...\n",
      "CPU times: user 15min 7s, sys: 1min 33s, total: 16min 41s\n",
      "Wall time: 16min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# pairs of (in-distribution, out-of-distribution) datasets to evaluate\n",
    "in_out_pairs = [\n",
    "    {\"in\": \"cifar-10\", \"out\": \"cifar-100\"},\n",
    "    {\"in\": \"cifar-100\", \"out\": \"cifar-10\"},\n",
    "    {\"in\": \"mnist\", \"out\": \"roman-numeral\"},\n",
    "    {\"in\": \"roman-numeral\", \"out\": \"mnist\"},\n",
    "    {\"in\": \"mnist\", \"out\": \"fashion-mnist\"},\n",
    "    {\"in\": \"fashion-mnist\", \"out\": \"mnist\"},\n",
    "]\n",
    "\n",
    "k_max = 110 # max k value for K nearest neighbor search\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for in_out_pair in in_out_pairs:\n",
    "    \n",
    "    in_dataset, out_dataset = in_out_pair[\"in\"], in_out_pair[\"out\"]\n",
    "    \n",
    "    # path to model trained on in-distribution train dataset\n",
    "    in_model_path = data_model_dict[in_dataset][\"model\"]\n",
    "\n",
    "    # get TEST datasets used for evaluation\n",
    "    in_test_dataset = data_model_dict[in_dataset][\"test_data\"]\n",
    "    out_test_dataset = data_model_dict[out_dataset][\"test_data\"]\n",
    "    \n",
    "    # class labels for the in-distribution test dataset\n",
    "    in_test_dataset_class_labels = in_test_dataset.label.values    \n",
    "    \n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"(in-distribution, out-of-distribution) dataset pair: \", in_dataset, out_dataset)\n",
    "    \n",
    "    # load model\n",
    "    print(\"  Loading model...\")\n",
    "    in_predictor_loaded = ImagePredictor.load(in_model_path)\n",
    "    \n",
    "    # Get test predicted probabilities\n",
    "    print(\"  Generating predicted probabilities...\")\n",
    "    in_pred_probs = in_predictor_loaded.predict_proba(data=in_test_dataset, as_pandas=False)\n",
    "    out_pred_probs = in_predictor_loaded.predict_proba(data=out_test_dataset, as_pandas=False)\n",
    "    \n",
    "    # Get LEARNED embeddings\n",
    "    print(\"  Extracting learned embeddings...\")\n",
    "    in_features = \\\n",
    "        np.stack(\n",
    "            in_predictor_loaded.predict_feature(data=in_test_dataset, as_pandas=False)[:, 0]\n",
    "        )\n",
    "    \n",
    "    out_features = \\\n",
    "        np.stack(\n",
    "            in_predictor_loaded.predict_feature(data=out_test_dataset, as_pandas=False)[:, 0]\n",
    "        )\n",
    "    \n",
    "    # Get pre-trained embeddings\n",
    "    in_pretrained_features = data_model_dict[in_dataset][\"test_data_pretrained_features\"]\n",
    "    out_pretrained_features = data_model_dict[out_dataset][\"test_data_pretrained_features\"]\n",
    "    \n",
    "    # Combine pred_probs and features\n",
    "    pred_probs = np.vstack([in_pred_probs, out_pred_probs])\n",
    "    features = np.vstack([in_features, out_features]) # LEARNED embeddings\n",
    "    pretrained_features = np.vstack([in_pretrained_features, out_pretrained_features])\n",
    "\n",
    "    # Create binary labels (1 = out-of-distribution)\n",
    "    in_labels = np.zeros(shape=len(in_pred_probs))\n",
    "    out_labels = np.ones(shape=len(out_pred_probs))\n",
    "    labels = np.hstack([in_labels, out_labels]) # OOD binary indicator\n",
    "    \n",
    "    print(\"  Running nearest neighbors search...\")\n",
    "    #### Compute nearest neighbors\n",
    "    \n",
    "    # nearest neighbors\n",
    "    nns = ApproxNearestNeighbors(\n",
    "            features=features, # LEARNED embeddings from the trained model\n",
    "            labels=labels,\n",
    "            ) # init Nearest Neighbor Scorer\n",
    "    nns.build_index() # build index for nearest neighbor lookup\n",
    "    neighbors_idx, neighbors_dist, neighbors_labels = nns.get_k_nearest_neighbors(k=k_max)\n",
    "    \n",
    "    print(\"  Generating scores...\")\n",
    "    #### Generate scores\n",
    "    one_minus_max_pred_prob = 1. - pred_probs.max(axis=1)\n",
    "    \n",
    "    entropy = get_normalized_entropy(pred_probs)\n",
    "    get_neighbor_entropy = np.vectorize(lambda idx: entropy[idx]) # Used to get entropy of neighbors\n",
    "    \n",
    "    get_neighbor_pred_probs = np.vectorize(lambda idx: pred_probs[idx], signature='()->(n)') # Used to get pred_probs of neighbors\n",
    "    \n",
    "    knn_k1_dist = neighbors_dist[:, :1].mean(axis=1)\n",
    "    \n",
    "    k = 5\n",
    "    knn_k5_entropy = (get_neighbor_entropy(neighbors_idx[:,:k]).sum(axis=1) + entropy) / (k + 1)\n",
    "    knn_k5_dist = neighbors_dist[:, :k].mean(axis=1)    \n",
    "    \n",
    "    k = 10\n",
    "    knn_k10_entropy = (get_neighbor_entropy(neighbors_idx[:,:k]).sum(axis=1) + entropy) / (k + 1)\n",
    "    knn_k10_dist = neighbors_dist[:, :k].mean(axis=1)\n",
    "    \n",
    "    k = 15\n",
    "    knn_k15_entropy = (get_neighbor_entropy(neighbors_idx[:,:k]).sum(axis=1) + entropy) / (k + 1)    \n",
    "    knn_k15_dist = neighbors_dist[:, :k].mean(axis=1)\n",
    "    \n",
    "    k = 100\n",
    "    knn_k100_entropy = (get_neighbor_entropy(neighbors_idx[:,:k]).sum(axis=1) + entropy) / (k + 1)    \n",
    "    knn_k100_dist = neighbors_dist[:, :k].mean(axis=1)\n",
    "    \n",
    "    # anomaly score (isolation forest)\n",
    "    anomaly_model = IsolationForest(random_state=0, n_estimators=100) # instantiate model\n",
    "    anomaly_model.fit(features) # out-of-sample extracted features\n",
    "    anomaly_score = 1 / anomaly_model.score_samples(features) # take the inverse so higher scores are more anomalous\n",
    "    \n",
    "    # entropy of KNN avg pred_probs\n",
    "    k = 10\n",
    "    neighbors_pred_probs = (get_neighbor_pred_probs(neighbors_idx[:,:k]).sum(axis=1) + pred_probs) / (k + 1)\n",
    "    entropy_knn_k10_pred_probs = get_normalized_entropy(neighbors_pred_probs)\n",
    "    \n",
    "        \n",
    "    #### Evaluate scores\n",
    "    auroc_one_minus_max_pred_prob = roc_auc_score(labels, one_minus_max_pred_prob)\n",
    "    \n",
    "    auroc_entropy = roc_auc_score(labels, entropy)\n",
    "\n",
    "    auroc_knn_k5_entropy = roc_auc_score(labels, knn_k5_entropy)\n",
    "    auroc_knn_k10_entropy = roc_auc_score(labels, knn_k10_entropy)\n",
    "    auroc_knn_k15_entropy = roc_auc_score(labels, knn_k15_entropy)\n",
    "    auroc_knn_k100_entropy = roc_auc_score(labels, knn_k100_entropy)\n",
    "    \n",
    "    auroc_entropy_knn_k10_pred_probs = roc_auc_score(labels, entropy_knn_k10_pred_probs)        \n",
    "\n",
    "    auroc_knn_k1_dist = roc_auc_score(labels, knn_k1_dist)\n",
    "    auroc_knn_k5_dist = roc_auc_score(labels, knn_k5_dist)\n",
    "    auroc_knn_k10_dist = roc_auc_score(labels, knn_k10_dist)\n",
    "    auroc_knn_k15_dist = roc_auc_score(labels, knn_k15_dist)    \n",
    "    auroc_knn_k100_dist = roc_auc_score(labels, knn_k100_dist)        \n",
    "\n",
    "    auroc_anomaly_score = roc_auc_score(labels, anomaly_score)\n",
    "    \n",
    "    results = {\n",
    "        \"in_distribution\": in_dataset,\n",
    "        \"out_of_distribution\": out_dataset,\n",
    "        \"auroc_one_minus_max_pred_prob\": auroc_one_minus_max_pred_prob,\n",
    "        \"auroc_entropy\": auroc_entropy,\n",
    "        \n",
    "        \"auroc_knn_k5_entropy\": auroc_knn_k5_entropy,\n",
    "        \"auroc_knn_k10_entropy\": auroc_knn_k10_entropy,\n",
    "        \"auroc_knn_k15_entropy\": auroc_knn_k15_entropy,\n",
    "        \"auroc_knn_k100_entropy\": auroc_knn_k100_entropy,\n",
    "        \n",
    "        \"auroc_entropy_knn_k10_pred_probs\": auroc_entropy_knn_k10_pred_probs,\n",
    "\n",
    "        \"auroc_knn_k1_dist\": auroc_knn_k1_dist,\n",
    "        \"auroc_knn_k5_dist\": auroc_knn_k5_dist,\n",
    "        \"auroc_knn_k10_dist\": auroc_knn_k10_dist,\n",
    "        \"auroc_knn_k15_dist\": auroc_knn_k15_dist,\n",
    "        \"auroc_knn_k100_dist\": auroc_knn_k100_dist,\n",
    "        \n",
    "        \"auroc_anomaly_score\": auroc_anomaly_score\n",
    "    }\n",
    "    \n",
    "    results_list.append(results)\n",
    "    \n",
    "    \n",
    "    #### Save pred_probs, embeddings, and OOD mask to Numpy files\n",
    "    \n",
    "    # Save files here\n",
    "    out_folder = f\"./test_data_in_{in_dataset}_out_{out_dataset}/\"\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    \n",
    "    np.save(out_folder + \"pred_probs.npy\", pred_probs)\n",
    "    np.save(out_folder + \"embeddings.npy\", features) # features = embeddings extracted from model trained on training dataset\n",
    "    np.save(out_folder + \"ood_mask.npy\", labels) # labels in this context is whether the datapoint is OOD! It's a binary indicator, True = OOD\n",
    "    \n",
    "    np.save(out_folder + \"in_distribution_test_dataset_class_labels.npy\", in_test_dataset_class_labels) # class labels for only the in-distribution test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aeb62f-15c9-4ce8-8c66-7855bad9d0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c44a2747-d5e8-43a4-b517-e366dcfcc1c6",
   "metadata": {},
   "source": [
    "## Put results to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04301c44-9d0e-4489-89a5-07f508f5a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2193a03-05e7-4227-a5c5-11cee9bdf84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_distribution</th>\n",
       "      <th>out_of_distribution</th>\n",
       "      <th>auroc_one_minus_max_pred_prob</th>\n",
       "      <th>auroc_entropy</th>\n",
       "      <th>auroc_knn_k10_entropy</th>\n",
       "      <th>auroc_entropy_knn_k10_pred_probs</th>\n",
       "      <th>auroc_knn_k10_dist</th>\n",
       "      <th>auroc_anomaly_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar-10</td>\n",
       "      <td>cifar-100</td>\n",
       "      <td>0.968904</td>\n",
       "      <td>0.968968</td>\n",
       "      <td>0.976455</td>\n",
       "      <td>0.977570</td>\n",
       "      <td>0.882912</td>\n",
       "      <td>0.890379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar-100</td>\n",
       "      <td>cifar-10</td>\n",
       "      <td>0.946950</td>\n",
       "      <td>0.955817</td>\n",
       "      <td>0.984437</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.602993</td>\n",
       "      <td>0.551464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnist</td>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>0.992383</td>\n",
       "      <td>0.994569</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.998381</td>\n",
       "      <td>0.967181</td>\n",
       "      <td>0.985315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.908997</td>\n",
       "      <td>0.929902</td>\n",
       "      <td>0.979364</td>\n",
       "      <td>0.930802</td>\n",
       "      <td>0.043762</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mnist</td>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>0.994458</td>\n",
       "      <td>0.995607</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.940788</td>\n",
       "      <td>0.929723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.913697</td>\n",
       "      <td>0.937726</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.959109</td>\n",
       "      <td>0.583062</td>\n",
       "      <td>0.527507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in_distribution out_of_distribution  auroc_one_minus_max_pred_prob  \\\n",
       "0        cifar-10           cifar-100                       0.968904   \n",
       "1       cifar-100            cifar-10                       0.946950   \n",
       "2           mnist       roman-numeral                       0.992383   \n",
       "3   roman-numeral               mnist                       0.908997   \n",
       "4           mnist       fashion-mnist                       0.994458   \n",
       "5   fashion-mnist               mnist                       0.913697   \n",
       "\n",
       "   auroc_entropy  auroc_knn_k10_entropy  auroc_entropy_knn_k10_pred_probs  \\\n",
       "0       0.968968               0.976455                          0.977570   \n",
       "1       0.955817               0.984437                          0.981527   \n",
       "2       0.994569               0.998846                          0.998381   \n",
       "3       0.929902               0.979364                          0.930802   \n",
       "4       0.995607               0.999404                          0.999130   \n",
       "5       0.937726               0.973560                          0.959109   \n",
       "\n",
       "   auroc_knn_k10_dist  auroc_anomaly_score  \n",
       "0            0.882912             0.890379  \n",
       "1            0.602993             0.551464  \n",
       "2            0.967181             0.985315  \n",
       "3            0.043762             0.001178  \n",
       "4            0.940788             0.929723  \n",
       "5            0.583062             0.527507  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"in_distribution\",\n",
    "    \"out_of_distribution\",\n",
    "    \"auroc_one_minus_max_pred_prob\",\n",
    "    \"auroc_entropy\",\n",
    "    \"auroc_knn_k10_entropy\",\n",
    "    \"auroc_entropy_knn_k10_pred_probs\",\n",
    "    \"auroc_knn_k10_dist\",\n",
    "    \"auroc_anomaly_score\"\n",
    "]\n",
    "\n",
    "df_results[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "750efd28-687d-42f0-9a55-32b7f7ef30be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_distribution</th>\n",
       "      <th>out_of_distribution</th>\n",
       "      <th>auroc_knn_k5_entropy</th>\n",
       "      <th>auroc_knn_k10_entropy</th>\n",
       "      <th>auroc_knn_k15_entropy</th>\n",
       "      <th>auroc_knn_k100_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar-10</td>\n",
       "      <td>cifar-100</td>\n",
       "      <td>0.975999</td>\n",
       "      <td>0.976455</td>\n",
       "      <td>0.975870</td>\n",
       "      <td>0.971511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar-100</td>\n",
       "      <td>cifar-10</td>\n",
       "      <td>0.982368</td>\n",
       "      <td>0.984437</td>\n",
       "      <td>0.985209</td>\n",
       "      <td>0.985393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnist</td>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>0.998231</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.997038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.971430</td>\n",
       "      <td>0.979364</td>\n",
       "      <td>0.983795</td>\n",
       "      <td>0.993706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mnist</td>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>0.999309</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>0.998886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.967805</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.976127</td>\n",
       "      <td>0.986394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in_distribution out_of_distribution  auroc_knn_k5_entropy  \\\n",
       "0        cifar-10           cifar-100              0.975999   \n",
       "1       cifar-100            cifar-10              0.982368   \n",
       "2           mnist       roman-numeral              0.998231   \n",
       "3   roman-numeral               mnist              0.971430   \n",
       "4           mnist       fashion-mnist              0.999309   \n",
       "5   fashion-mnist               mnist              0.967805   \n",
       "\n",
       "   auroc_knn_k10_entropy  auroc_knn_k15_entropy  auroc_knn_k100_entropy  \n",
       "0               0.976455               0.975870                0.971511  \n",
       "1               0.984437               0.985209                0.985393  \n",
       "2               0.998846               0.998859                0.997038  \n",
       "3               0.979364               0.983795                0.993706  \n",
       "4               0.999404               0.999393                0.998886  \n",
       "5               0.973560               0.976127                0.986394  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"in_distribution\",\n",
    "    \"out_of_distribution\",\n",
    "    \"auroc_knn_k5_entropy\",\n",
    "    \"auroc_knn_k10_entropy\",\n",
    "    \"auroc_knn_k15_entropy\",\n",
    "    \"auroc_knn_k100_entropy\",\n",
    "]\n",
    "\n",
    "df_results[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "472e93f8-5058-4e56-b70a-f8ffdbd3f866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_distribution</th>\n",
       "      <th>out_of_distribution</th>\n",
       "      <th>auroc_knn_k1_dist</th>\n",
       "      <th>auroc_knn_k5_dist</th>\n",
       "      <th>auroc_knn_k10_dist</th>\n",
       "      <th>auroc_knn_k15_dist</th>\n",
       "      <th>auroc_knn_k100_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar-10</td>\n",
       "      <td>cifar-100</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.870990</td>\n",
       "      <td>0.882912</td>\n",
       "      <td>0.890921</td>\n",
       "      <td>0.952323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar-100</td>\n",
       "      <td>cifar-10</td>\n",
       "      <td>0.610539</td>\n",
       "      <td>0.608929</td>\n",
       "      <td>0.602993</td>\n",
       "      <td>0.597227</td>\n",
       "      <td>0.466928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnist</td>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>0.961315</td>\n",
       "      <td>0.965429</td>\n",
       "      <td>0.967181</td>\n",
       "      <td>0.968263</td>\n",
       "      <td>0.975588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roman-numeral</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.073345</td>\n",
       "      <td>0.051868</td>\n",
       "      <td>0.043762</td>\n",
       "      <td>0.039027</td>\n",
       "      <td>0.013868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mnist</td>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>0.934976</td>\n",
       "      <td>0.939818</td>\n",
       "      <td>0.940788</td>\n",
       "      <td>0.941378</td>\n",
       "      <td>0.945835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fashion-mnist</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.568013</td>\n",
       "      <td>0.577871</td>\n",
       "      <td>0.583062</td>\n",
       "      <td>0.586229</td>\n",
       "      <td>0.598909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in_distribution out_of_distribution  auroc_knn_k1_dist  auroc_knn_k5_dist  \\\n",
       "0        cifar-10           cifar-100           0.844101           0.870990   \n",
       "1       cifar-100            cifar-10           0.610539           0.608929   \n",
       "2           mnist       roman-numeral           0.961315           0.965429   \n",
       "3   roman-numeral               mnist           0.073345           0.051868   \n",
       "4           mnist       fashion-mnist           0.934976           0.939818   \n",
       "5   fashion-mnist               mnist           0.568013           0.577871   \n",
       "\n",
       "   auroc_knn_k10_dist  auroc_knn_k15_dist  auroc_knn_k100_dist  \n",
       "0            0.882912            0.890921             0.952323  \n",
       "1            0.602993            0.597227             0.466928  \n",
       "2            0.967181            0.968263             0.975588  \n",
       "3            0.043762            0.039027             0.013868  \n",
       "4            0.940788            0.941378             0.945835  \n",
       "5            0.583062            0.586229             0.598909  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"in_distribution\",\n",
    "    \"out_of_distribution\",\n",
    "    \"auroc_knn_k1_dist\",\n",
    "    \"auroc_knn_k5_dist\",\n",
    "    \"auroc_knn_k10_dist\",\n",
    "    \"auroc_knn_k15_dist\",\n",
    "    \"auroc_knn_k100_dist\",\n",
    "]\n",
    "\n",
    "df_results[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aac17a-316a-4871-b4c9-c574c92f36eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899cbab-ef6f-4057-bdad-8f723c6bc4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37059fc3-1691-4e66-be72-7ebd9fb36488",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab608e7-b94a-4f18-b843-00d1cb16302b",
   "metadata": {},
   "source": [
    "## Load pred_probs, OOD mask, and class labels for in-distribution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa04415-0290-4e19-86dd-d4744ef434c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544a6a7-e112-4cb8-ab01-37c9c2c7de7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2aecf28f-5985-4aed-8d3e-4fe0b6a6ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dataset = \"cifar-10\"\n",
    "out_dataset = \"cifar-100\"\n",
    "\n",
    "out_folder = f\"./test_data_in_{in_dataset}_out_{out_dataset}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63635b6d-2483-416f-b161-6cf574790cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = np.load(out_folder + \"pred_probs.npy\")\n",
    "ood_mask = np.load(out_folder + \"ood_mask.npy\")\n",
    "\n",
    "# NOTE: this contains only the class labels for the in-distribution test dataset!\n",
    "in_distribution_test_dataset_class_labels = np.load(out_folder + \"in_distribution_test_dataset_class_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a2dc320-16e5-4bb1-9af1-e9578cb3d2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "320f1c9f-d490-4730-87c2-a216c77e8e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "679a21de-edcf-43bf-9399-6a3f0e2c647a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_distribution_test_dataset_class_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2ba69ced-7319-47a1-80e2-5835752385e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "(pred_probs[:10000].argmax(axis=1) == in_distribution_test_dataset_class_labels).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
